<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Ryan Kwong, Lemuel Sumardy</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-ilovethomas/hw3/">cal-cs184-student.github.io/hw-webpages-ilovethomas/hw3/</a>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-ilovethomas-3">github.com/cal-cs184-student/sp25-hw3-ilovethomas-3</a>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		In this project, we implemented a ray tracer that is able to provide realistic and rich lighting on 3D objects thruogh direct and indirect lighting as well as efficient lighting through the use of BVHs and adaptive sampling.

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		<h4>Ray Generation</h4>
		To generate a ray, we need to convert the target coordinates from the image space to the camera space using \(x_{camera}=2x_{image}\tan(hFov/2)\) and \(y_{camera}=2y_{image}\tan(vFov/2)\) and then using the <code>c2w</code> matrix. Once we can generate rays from the camera, we are then able to implmen this in the pathtracer. Given the <code>gridSampler</code>, we can uniformly sample pixels in the image, normalize the coordniates and generate rays to start ray tracing. We can then call <code>set_radiance_global_illumination</code>, which for now returns the normal shading, and write the resulting pixel color to th buffer and update.

		<h4>Ray-Triangle Intersection</h4>
		For ray-triangle intersection, we used the Moller-Trumbore algorithm, which is defined as follows:
		<ul>
			<li>Given the three points of the triangle \(\vec{v_0}, \vec{v_1}, \vec{v_2}\), we can express any point inside the triangle as \(\vec{P}=\vec{v_0}+\alpha(\vec{v_1}-\vec{v_0})+\beta(\vec{v_2}-\vec{v_0})\)</li>
			<li>By substituting the ray equaiton \(\vec{r}(t)=\vec{O}+t\vec{D}\) into the triangle point intersection equation, we are able to simplify the equation down to a quadratic equation \(\vec{O}-\vec{v_0}=-t\vec{D}+\alpha(\vec{v_1}-\vec{v_0})+\beta(\vec{v_2}-\vec{v_0})\)</li>
			<li>To solve for \(t,\alpha,\beta \), we can solve the matrix equation (Latex matrix formatting doesn't work for some reason)
				\[ [-\vec{D} \vec{E_1} \vec{E_2}][t \alpha \beta]^\top=\vec{T}
				\]
			where \(\vec{E_1}=\vec{v_1}-\vec{v_0}, \vec{E_2}=\vec{v_2}-\vec{v_0}, \vec{T}=\vec{O}-\vec{v_0}\)</li>
			<li>We can determine of the point is inside the triangle by checking if \(t>0, 0\leq\alpha\leq 1, 0\leq\beta\leq 1, \alpha+\beta\leq 1\). If these conditions are met, the ray intersects the triangle at time \(t\).<li>
		</ul>
		<h4>Ray-Sphere Intersection</h4>
		Give the ray equation \(\vec{r}(t)=\vec{O}+t\vec{D}\) where \(\vec{O}\) is the origin vector and \(\vec{D}\) is the direction vector, we can calculate the intersections by substituting the ray equation into the sphere equation \(\vec{P}-\vec{C}=r^2\) for any arbitrary point \(\vec{P}\) for a sphere with center \(\vec{C}\) and radius \(r\). With this substitution we can simplify to get the quadratic equation \[t^2(\vec{D}\cdot\vec{D})+2t(\vec{v}\cdot\vec{D})-\vec{v}\cdot\vec{v}-r^2=0\]	
		where \(\vec{v}=\vec{O}-\vec{C}\). Given two real solutions \(t_1, t_2, t_2>t_1\), we know that the ray enters the sphere at \(t_1\) and leaves at \(t_2\). If there is one real solution, the ray is tangent to the sphere and if there are no real solutions, the ray does not intersect the sphere.

		<p>Here are some example normal shadings:</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 1/cow.png" width="400px"/>
				  <figcaption>cow.dae normal shading</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 1/CBempty.png" width="400px"/>
				  <figcaption>CBempty.dae normal shading</figcaption>
				</td>
			  </tr>
				<tr>
					<td style="text-align: center;">
						<img src="Images/Part 1/CBspheres.png" width="400px"/>
						<figcaption>CBspheres.dae normal shading</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Images/Part 1/part_1_gems.png" width="400px"/>
						<figcaption>CBgems.dae normal shading</figcaption>
					</td>
					</tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		We chose a simple bounding heuristic. The program does a simple check of which dimension of the bounding box is largest. This way, we can most effectively split the primitives evenly. To choose the split position, we used the median element, as it was a simple, yet effective way of distributing primitives so that the \(O(\log_2(n))\) efficiency could be taken advantage of.
		<br><br>
		We chose to use <code>cow.dae</code> as our benchmark. The rendering time without the BVH implementation took 35.85 seconds. However, when we implement the BVH, our rendering time was 0.081 seconds. This makes sense because based on the pathtracer debugging statements, <code>cow.dae</code> contians 5856 primitives. This means on average, the BVH should perform 450 times faster than the regular intersection for loop, which we can see is true. We can see similar results in <code>banana.dae</code> and <code>teapot.dae</code> whose non-BVH vs BVH times were 22.15s vs 0.061 and 20.41s vs 0.058s, respectively.  
		
		<h3>Images with normal shading from large .dae files</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 2/part2_blob.png" width="400px"/>
				  <figcaption>blob.dae normal shading</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 2/part2_dragon.png" width="400px"/>
				  <figcaption>CBdragon.dae normal shading</figcaption>
				</td>
			  </tr>
				<tr>
					<td style="text-align: center;">
						<img src="Images/Part 2/part2_lucy.png" width="400px"/>
						<figcaption>lucy.dae normal shading</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Images/Part 2/part2_maxplanck.png" width="400px"/>
						<figcaption>maxplanck.dae normal shading</figcaption>
					</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="Images/Part 2/part2_walle.png" width="400px"/>
							<figcaption>wall-e.dae normal shading</figcaption>
						</td>

						</tr>
			</table>
		</div>
		<h2>Part 3: Direct Illumination</h2>
		For <code>estimate_direct_lighting_hemisphere</code>, we simply sampled rays uniformly throughout the hemisphere. If the ray is interseccts the BVH, it calculated the output radiance based on the BSDF. In <code>estimate_direct_lighting_importance</code>, we iterated through all the light sources and dtermined whether they were point sources. Then, like the hemisphere direct lighting function, if the emitted ray intersects a BVH, we used the BSDF to calcualte the reflected light, and added it to the total light output. 
		<h3>Images rendered with importance and hemisphere sampling</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 3/part_3_spheres_hemisphere.png" width="400px"/>
				  <figcaption>CBspheres.dae hemisphere</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 3/part_3_spheres_important.png" width="400px"/>
				  <figcaption>CBSpheres.dae importance</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 3/part_3_bunny_hemisphere.png" width="400px"/>
				  <figcaption>CBbunny.dae hemisphere</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 3/part_3_bunny_important.png" width="400px"/>
				  <figcaption>CBbunny.dae importance</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>The comparison of hemisphere sampling versus importance sampling has numerous
			distinct characteristics. Hemisphere sampling produces
			noisier images with brighter but inconsistent/sharper illumination.
			Importance sampling generates cleaner results and more consistent shadows 
			but appears slightly darker overall.
			This happens because importance sampling prioritizes 
			directions with greater light contribution.</p>

		<h3>Comparison of scene with different number light rays</h3>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 3/part_3_s_1.png" width="400px"/>
				  <figcaption>CBbunny.dae with 1 light ray</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 3/part_3_s_4.png" width="400px"/>
				  <figcaption>CBbunny.dae with 4 light ray</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 3/part_3_s_16.png" width="400px"/>
				  <figcaption>CBbunny.dae with 16 light ray</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 3/part_3_s_64.png" width="400px"/>
				  <figcaption>CBbunny.dae with 64 light ray</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>The comparison of renders above with increasing light ray counts
			shows how image quality in soft shadows improves as the number of light rays increase. 
			At 1 ray, there is excessive noise that obscures the details
			 and creates grainy shadows. At 4 rays, there is a modest improvement but it still
			  shows visible artifacts. At 16 rays, most of the distracting noise
				 disappears. Finally, the 64 ray render has the cleanest result
				  with well-defined shadows and clear details. This demonstrates
					 how higher ray counts reduce variance in Monte Carlo integration,
					  which in turn improves areas with complex light interactions like
						 soft shadows.</p>
		<h2>Part 4: Global Illumination</h2>
		<p>
			Indirect illumination occurs when light bounces off multiple surfaces before reaching the camera.
			The function at_least_one_bounce_radiance handles the indirect lighting computation.
			It first sets up a coordinate system at the hit point using the surface normal.
			Then direct illumination is calculated using the one_bounce_radiance function.
			For indirect illumination, a russian roulette with probability 0.25 to terminate is used.
			The BSDF is sampled to get a new direction and the direction is then transformed to
			to the world coordinates. A ray is then created from the origin to that direction.
			If the ray intersects another object, the function recursively traces it, repeating 
			this logic. The contribution is weighed by BSDF value f, cos(theta) and divided by the pdf
			and continuation probability. at_least_one_bounce_radiance returns the sum of direct illumination and 
			indirect illumination.
		</p>
		<h3>Images rendered with global illumination</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/global-illumination/global_illum_bench.png" width="400px"/>
				  <figcaption>bench.dae</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/global-illumination/global_illum_blob.png" width="400px"/>
				  <figcaption>blob.dae</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/global-illumination/global_illum_bunny.png" width="400px"/>
				  <figcaption>bunny.dae</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/global-illumination/global_illum_dragon.png" width="400px"/>
				  <figcaption>dragon.dae</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h3>Comparison of only direct and indirect illumination</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/direct-vs-indirect/bunny_direct_only.png" width="400px"/>
				  <figcaption>CBbunny.dae direct lighting only</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/direct-vs-indirect/bunny_indirect_only.png" width="400px"/>
				  <figcaption>CBbunny.dae indirect lighting only</figcaption>
				</td>
			</table>
		</div>
		<p>
			CBbunny with direct lighting only is an image of the bunny illuminated 
			by the light coming directly from the ceiling light. The lighting appears
			more focused and creates stronger shadows under the bunny. For the image with
			indirect lighting only, there is a softer, more diffuse lighting effect through the scene,
			which makes the scene much darker compared to the direct lighting scene. The
			color from the walls also contributes through color bleeding where surfaces near
			the color like floor, next door walls and the bunny have subtle shades of red and blue.
		</p>
		<h3>CBbunny.dae with isAccumBounces=false</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/no-accumulate/bunny_off_0.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=0</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/no-accumulate/bunny_off_1.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=1</figcaption>
				</td>
			  </tr>
				<tr>
					<td style="text-align: center;">
						<img src="Images/Part 4/no-accumulate/bunny_off_2.png" width="400px"/>
						<figcaption>CBbunny.dae with m=2</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Images/Part 4/no-accumulate/bunny_off_3.png" width="400px"/>
						<figcaption>CBbunny.dae with m=3</figcaption>
					</td>
					</tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/no-accumulate/bunny_off_4.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/no-accumulate/bunny_off_5.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=5</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>
			The 2nd and 3rd bounce images (m=2 and m=3) are important because they add 
			indirect illumination effects that aren't possible with only rasterization.
			As mentioned previously above, the indirect lighting scene added things like
			subtle lighting, softer shadows and color bleeding which can once again be 
			scene in the images of only the 2nd bounce and the 3rd bounce. The softer shadows
			and color bleeding are more apparent in the 2nd bounce. The 3rd bounce contributes
			less than the 2nd but still contributes to the overall quality of the rendered image
			by adding some indirect light/shading. This is superior to traditional methods of
			rasterization because rasterization does not put into account things like
			lighting and color bleeding from lighting creating a less realistic image.
		</p>
		<h3>CBbunny.dae with isAccumBounces=true</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/accumulate/bunny_on_0.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=0</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/accumulate/bunny_on_1.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=1</figcaption>
				</td>
			  </tr>
				<tr>
					<td style="text-align: center;">
						<img src="Images/Part 4/accumulate/bunny_on_2.png" width="400px"/>
						<figcaption>CBbunny.dae with m=2</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Images/Part 4/accumulate/bunny_on_3.png" width="400px"/>
						<figcaption>CBbunny.dae with m=3</figcaption>
					</td>
					</tr>
					
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/accumulate/bunny_on_4.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/accumulate/bunny_on_5.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=5</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>The comparison between the rendered views of unaccumulated and accumulated
			bounces for CBbunny.dae shows how each light bounce contributes to the 
			final rendered scene. m=0 shows the light directly from light sources.
			m=1 shows direct illumination, providing basic lighting. This can be seen 
			in the accumulated image where the bunny has sharp lighting, dramatic lighting.
			Then when m=2, subtle lighting is added and the accumulated image's dramatic
			lighting disappears and is replaced with subtle shading. The color bleeding also shows up.
			For m=3, m=4, and m=5 their contributions are minimal and only provide subtle refinements.
			This is why their images in the unaccumulated view is so dark.
		</p>
		<h3>CBbunny.dae with Russian Roulette rendering</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/accumulate/bunny_on_0.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=0</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/accumulate/bunny_on_1.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=1</figcaption>
				</td>
			  </tr>
				<tr>
					<td style="text-align: center;">
						<img src="Images/Part 4/accumulate/bunny_on_2.png" width="400px"/>
						<figcaption>CBbunny.dae with m=2</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Images/Part 4/accumulate/bunny_on_3.png" width="400px"/>
						<figcaption>CBbunny.dae with m=3</figcaption>
					</td>
				</tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/accumulate/bunny_on_4.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/bunny_roulete_100.png" width="400px"/>
				  <figcaption>CBbunny.dae with m=100</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h3>dragon.dae with various sample-per-pixel rates</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/Various-sample-rates/various_samples_1.png" width="400px"/>
				  <figcaption>dragon.dae with s=1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/Various-sample-rates/various_samples_2.png" width="400px"/>
				  <figcaption>dragon.dae with s=2</figcaption>
				</td>
			  </tr>
				<tr>
					<td style="text-align: center;">
						<img src="Images/Part 4/Various-sample-rates/various_samples_4.png" width="400px"/>
						<figcaption>dragon.dae with s=4</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Images/Part 4/Various-sample-rates/various_samples_8.png" width="400px"/>
						<figcaption>dragon.dae with s=8</figcaption>
					</td>
				</tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/Various-sample-rates/various_samples_16.png" width="400px"/>
				  <figcaption>dragon.dae with s=16</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 4/Various-sample-rates/various_samples_64.png" width="400px"/>
				  <figcaption>dragon.dae with s=64</figcaption>
				</td>
			  </tr>
				<td style="text-align: center;">
				  <img src="Images/Part 4/Various-sample-rates/various_samples_1024.png" width="400px"/>
				  <figcaption>dragon.dae with s=1024</figcaption>
				</td>
			</table>
		</div>
		<p>At s=1 and s=2, the images are extremely noisy with significant grainy artifacts throughout.
			Then at s=4, the noise starts to decrease and the dragons shape becomes more defined. 
			This pattern continues as the sample-per-pixel rates increase. At s=1024, the image is 
			incredibly clear and has no visible noise or artifacting.
		</p>
		<h2>Part 5: Adaptive Sampling</h2>
		<p>
			Adaptive sampling is a technique that aims to fix the problem
			of a fixed high number of samples per pixel by changing the number of samples
			in different parts of the image. This is done by putting more samples
			in more difficult parts of an image and fewer samples in regions that 
			converge quickly. This is done by dynamically determining whether 
			a pixel has converged.
		</p>
		<p>
			Our implementation starts as follows. First the code initializes s1 and s2,
			which are sums of the sampled values and sums of the squared sample values.
			Then samples are taken in batches defined by samplesPerBatch. For each sample,
			there is a random offset inside the pixel taken by using gridSampler->get_sample().
			A camera ray is created and traced into that and the resulting radiance is added to s1
			and its square to s2. After each batch, we calculate the mean, variance, standard deviation,
			and then I where I = 1.96 * pixel_std_dev / sqrt(samples). If I ≤ maxTolerance * mean_illuminance
			then it has converged and we stop sampling. The final color is the average of all the samples.
		</p>
		<h3>Renders with adaptive sampling rate</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 5/bunny_5.png" width="400px"/>
				  <figcaption>CBbunny.dae render</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 5/bunny_5_rate.png" width="400px"/>
				  <figcaption>CBbunny.dae rate</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="Images/Part 5/spheres_norm_5.png" width="400px"/>
				  <figcaption>CBspheres.dae render</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Images/Part 5/spheres_norm_5_rate.png" width="400px"/>
				  <figcaption>CBspheres.dae rate</figcaption>
				</td>
			  </tr>
			</table>
		</div>		
		<h2>How we collaborated and what we learned</h2>
		<p>We worked together by systematically working on one section together and systematically debugging any issues that arose. This was especially useful for debugging unseen issues in previous parts. For example, a lighting bug we missed in Part 3 caused us issues in Parts 4 and 5. Because we worked together in this fashion, we were able to identify the issue. Overall, we learned how a path tracer generates rays, detects collisions of the rays onto objects, and how to calculate the output light from the object’s BSDF. We also learned how to debug the recursive errors in indirect lighting, incorrect sampling rates, and errors in calculating collisions using a BVH.</p>
		</div>
		
	</body>
</html>